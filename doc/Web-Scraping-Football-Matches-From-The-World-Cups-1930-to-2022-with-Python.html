<!DOCTYPE html>
<html class="type--html">
	<head>
		<meta charset="utf-8" />
		<title>Web Scraping Football Matches From The World Cups 1930 to 2022 with Python</title>

		<style type="text/css">
			:root {
	--main-font: Palatino, 'Palatino Linotype', 'Times New Roman', 'Droid Serif',
		Times, 'Source Serif Pro', serif, 'Apple Color Emoji', 'Segoe UI Emoji',
		'Segoe UI Symbol';
	--alt-font: 'helvetica neue', ubuntu, roboto, noto, 'segoe ui', arial,
		sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';
	--code-font: Menlo, Consolas, monospace;
	--accent-color: black;
}

@page {
	size: A5 portrait;
	margin: 1cm 1cm 2cm;
}

html {
	font-size: 12pt;
	line-height: 1.3;
	font-family: var(--main-font);
	-webkit-print-color-adjust: exact;
}

h1,
h2,
h3,
h4,
h5,
h6 {
	margin-bottom: 0.5em;
	font-family: var(--alt-font);
	font-weight: bold;
	page-break-after: avoid;
	page-break-inside: avoid;
}

/*
	Prevent dangling headings at the end of the page.

	See:
	
	* https://github.com/danburzo/percollate/issues/110
	* https://stackoverflow.com/a/53742871/21613
 */
h1::after,
h2::after,
h3::after,
h4::after,
h5::after,
h6::after {
	content: '';
	display: block;
	height: 5rem;
	margin-bottom: -5rem;
}

a {
	color: inherit;
	text-decoration: underline;
}

/*
	Going on a limb here,
	but a.anchor in heading elements
	is most likely a '#' or '§' anchor
	we don't want to display in the PDF.
 */
h1 a.anchor,
h2 a.anchor,
h3 a.anchor,
h4 a.anchor,
h5 a.anchor,
h6 a.anchor {
	visibility: hidden;
	position: absolute;
}

th {
	font-family: var(--alt-font);
}

code,
pre {
	font-size: 0.85em;
}

pre code {
	font-size: 1em;
}

/*
	Don't display hidden elements
 */
[hidden],
[aria-hidden] {
	display: none;
}

/*
	Table of Contents page
	----------------------------------------------------
 */

.toc {
	page-break-before: always;
	page-break-after: always;
}

/*
	Article formatting
	----------------------------------------------------
 */

article {
	font-size: 1em;
	hyphens: auto;
}

article:not(:last-of-type) {
	page-break-after: always;
}

/*
	Article Header
	--------------
 */

.article__header {
	margin: 0 0 1.3em;
}

.article__title {
	font-size: 2.4em;
	margin: 0 0 0.25em;
	letter-spacing: -0.03em;
	line-height: 1.1;
}

.article__url {
	font-style: italic;
	font-size: 0.9em;
}

/*
	Article Content
	---------------
 */

.article__content img {
	max-width: 100%;
	display: block;
	margin: 0 auto;
}

.article__content figure {
	display: block;
	margin: 1.5em 0;
	padding: 0;
	text-align: center;
}

.article__content figcaption {
	font-size: 0.8em;
	font-family: var(--alt-font);
	margin: 0.81em 0;
	line-height: 1.625;
}

.article__content figure blockquote,
.article__content figure pre {
	text-align: left;
}

.article__content table,
.article__content figure {
	page-break-inside: avoid;
}

.article__content pre,
.article__content code {
	font-family: var(--code-font);
}

.article__content pre {
	border: 0.25pt solid #000;
	padding: 0.75em;
	font-size: 0.9em;
	white-space: pre-wrap;
	word-wrap: break-word;
}

.article__content kbd,
.article__content var,
.article__content samp {
	padding: 0 0.5em;
	box-shadow: 2pt 2pt 0 #ccc;
	border: 0.5pt solid #000;
	border-radius: 0.25em;
	font-size: 0.9em;
}

.article__content p {
	margin: 0;
	orphans: 3;
	widows: 3;
}

/*
	Indent all subsequent paragraphs.
 */
.article__content p + p {
	text-indent: 2em;
}

/*
	Fixes the text indent for images
	that get wrapped in a <p> tag
	by Readability.

	Reference:
	https://github.com/danburzo/percollate/issues/48
 */
.article__content p + p > img:only-child {
	margin-left: -2em;
}

.article__content hr {
	border: none;
	height: 0.5pt;
	margin: 1.3em 0;
	background: #000;
}

.article__content blockquote {
	font-size: 0.9em;
	line-height: 1.44;
	padding-left: 2em;
	border-left: 3pt solid #000;
	margin-left: 0;
}

.article__content table {
	width: 100%;
	border-collapse: collapse;
	page-break-inside: auto;
	font-size: 0.9em;
	line-height: 1.44;
	margin: 1.44em 0;
}

.article__content th {
}

.article__content th,
.article__content td {
	text-align: left;
	vertical-align: top;
	padding: 0.36em 1em 0.36em 0;
}

.article__content tr {
	border-bottom: 0.25pt solid #000;
	page-break-inside: avoid;
	page-break-after: auto;
}

.article__content dt {
	font-weight: bold;
}

.article__content ol,
.article__content ul {
	padding-left: 2em;
	list-style-position: outside;
	margin: 0.65em 0;
}

.article__content aside {
	font-family: var(--alt-font);
	font-size: 0.9em;
	line-height: 1.44;
	padding-left: 2em;
}

.article__content details {
	margin: 0.65em 0;
}

.article__content details > summary {
	font-weight: bold;
	font-size: 0.9em;
	font-family: var(--alt-font);
}

/*
	Page header / footer
	--------------------

	These are extracted when generating the PDF
	and are not subject to the page's CSS cascade.

	They're just placed here for easier style coordination
 */

.header-template {
}

.footer-template {
	font-size: 10pt;
	font-weight: bold;
}

/*
	Cover page
	----------
 */

.cover {
	color: var(--accent-color);
	border: 0.5em solid;
	font-family: var(--cover-font, var(--alt-font));
	padding: 2em;
}

.cover__author {
	margin: 1em 0;
	font-weight: bold;
}

.cover__title {
	font-size: 2.4em;
	margin: 0;
	line-height: 1.1;
}

.cover__subtitle {
	margin: 1em 0;
}

.cover__date {
	font-weight: bold;
}

/*
	Filetype specific
	-----------------
 */

.type--pdf body {
	margin: 0;
	padding: 0;
}

.type--pdf a:not(.no-href)::after {
	content: ' → ' attr(href) '';
	font-size: 0.8em;
	word-break: break-all;
	word-wrap: break-word;
	font-family: var(--alt-font);
}

.type--pdf .cover,
.type--epub .cover {
	position: absolute;
	overflow: hidden;
}

.type--pdf .cover {
	top: 0;
	left: 0;
	right: 0;
	bottom: 0;
}

.type--epub .cover {
	top: 2em;
	left: 2em;
	right: 2em;
	bottom: 2em;
}

.type--pdf .cover__content,
.type--epub .cover__content {
	position: absolute;
	top: 30%;
	left: 2em;
	right: 2em;
	transform: translate(0, -50%);
}

.type--pdf .cover__sentinel {
	page-break-after: always;
}

		</style>
	</head>
	<body>
		  
		<article id="percollate-page-3ae37a10-6afd-11ed-8330-bf134d79365d" class="article" lang="en">
			<header class="article__header">
				<h1 class="article__title">Web Scraping Football Matches From The World Cups 1930 to 2022 with Python</h1>
				
				<p class="article__url">
					Source:
					<a class="no-href" href="https://scribe.rip/geekculture/web-scraping-football-matches-from-the-world-cups-1930-to-2022-with-python-d2a1d578f034">https://scribe.rip/geekculture/web-scraping-football-matches-from-the-world-cups-1930-to-2022-with-python-d2a1d578f034</a>
				</p>
			</header>

			<div class="article__content"><div class="page" id="readability-page-1"><article><section><h3>Real-world data science project using Python. Part 1: Scraping football matches with Beautiful Soup.</h3><figure><img src="https://cdn-images-1.medium.com/fit/c/800/450/0*6YImrjzvKwM2O6sA"><label for="14370092435699918925">✍︎</label><span>Photo by <a href="https://unsplash.com/@fznsr_?utm_source=medium&amp;utm_medium=referral">Fauzan Saari</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral">Unsplash</a></span></figure><p>The World Cup 2022 is coming and what better way to learn data science and Python than solving a real-world project?</p><p>But we can’t start a project without data, so, in this guide, we’ll use Python and Beautiful Soup to extract data from all the world cups played so far (1930–2018) and the fixture of the world cup 2022.</p><p>This guide is part of a series of articles where I attempt to predict the winner of the World Cup 2022 using Python. All the articles will be added to this <a href="https://frank-andrade.medium.com/list/python-project-fifa-world-cup-2022-prediction-85426e7c421c">list</a>.</p><h3>Installing the libraries</h3><p>In this tutorial, we’ll use <code>bs4</code> to scrape websites, <code>lxml</code> to parse HTML documents, and <code>requests</code> to send requests to the target website.</p><p>Here’s the command you need to run in the terminal to install these libraries.</p><figure><pre>pip install bs4
pip install lxml
pip install requests</pre></figure><p>In addition to the previous libraries, we’ll install pandas to better manage the data we’re going to extract.</p><figure><pre>pip install pandas</pre></figure><p>Now let’s start coding!</p><h2>Part 1: Scraping data from one World Cup</h2><p>In this tutorial, we’re going to scrape data from all the world cups played so far. That said, to make this guide friendly, we’ll start by scraping data from one world cup — <a href="https://en.wikipedia.org/wiki/2014_FIFA_World_Cup">Brazil 2014</a>. In part 2, we’ll use the code written in part 1 to extract data from all the world cups.</p><h3>Importing the libraries</h3><p>Let’s start by importing the libraries we installed before.</p><figure><pre>import pandas as pd
from bs4 import BeautifulSoup
import requests</pre></figure><p>Note that we don’t need to import <code>lxml</code> since it’s only a dependency that bs4 needs to work properly.</p><h3>Creating a soup</h3><p>To extract data with Beautiful Soup we need to create a soup. This soup uses the <code>lxml</code> parser we installed before and also the HTML content that will be parsed.</p><p>To get the HTML content of a website we need to send a request to the website and then get the text of the response.</p><figure><pre>web = 'https://en.wikipedia.org/wiki/2014_FIFA_World_Cup'
response = requests.get(web)
content = response.text
soup = BeautifulSoup(content, 'lxml')</pre></figure><h3>Extracting all the matches from the World Cup</h3><p>Now it’s time to web scrape football matches. To do so, we have to identify a pattern that allows us to scrape not only one but all the matches of the competition.</p><p>To easily find one pattern, first, we have to inspect the website by right-clicking and selecting “Inspect.” After this, developer tools will pop up. You can navigate through the HTML using the button below.</p><figure><img src="https://cdn-images-1.medium.com/fit/c/40/43/1*Bad09h0TD97jPiJwXXQzAw.png"><label for="789164980454196069">✍︎</label><span></span></figure><p>Here’s one pattern I found after exploring the website.</p><figure><img src="https://cdn-images-1.medium.com/fit/c/800/459/1*8f37AR626NHh-5FzbshOPg.png"><label for="789164980454196069">✍︎</label><span></span></figure><p>As you can see every match played is inside a row that is represented by the HTML node highlighted in blue above.</p><p>Now to extract all the matches with our <code>soup</code> we have to use the .find_all method. This method needs 2 inputs: the tag name and the class name.</p><figure><pre>matches = soup.find_all('div', class_='footballbox')</pre></figure><p>I’ve stored all the rows inside a list I called <code>matches</code>.</p><h3>Extracting the home/away teams and score data of every match</h3><p>Now that we have all the matches inside our <code>matches</code> list, we have to loop through it to extract specific information.</p><p>In this case, we’ll extract the home/away team and score data. Then we’ll store them inside empty lists, so we can later put them in a table.</p><p>To get the home team data, we need to inspect it first, then we have to copy the tag name and class name. The same goes for the score and away team.</p><figure><img src="https://cdn-images-1.medium.com/fit/c/800/452/1*bj-y7erZc2HZZbCjALH9gQ.png"><label for="789164980454196069">✍︎</label><span></span></figure><p>Finally, we get the text of an element by using <code>.get_text</code> .</p><figure><pre>home = []
score = []
away = []

for match in matches:
    home.append(match.find('th', class_='fhome').get_text())
    score.append(match.find('th', class_='fscore').get_text())
    away.append(match.find('th', class_='faway').get_text())</pre></figure><h3>Storing our data in a dataframe and exporting data to a CSV file</h3><p>Dataframes are good for managing data in Python. We’ll create a dataframe from the home, score, and away lists. In addition to that, we’ll create a column named “year” that will contain the year of the world cup (2014 for this particular case)</p><figure><pre>dict_football = {'home': home, 'score': score, 'away': away}
df_football = pd.DataFrame(dict_football)
df_football['year'] = 2014</pre></figure><p>Finally, we export the dataframe to a CSV file.</p><figure><pre>df_fifa.to_csv("fifa_worldcup_historical_data.csv", index=False)</pre></figure><h2>Part 2: Scraping data from ALL the World Cups</h2><p>Now that we know how to scrape one world cup is time to scrape them all! To do so, first, we need to find a pattern in the links.</p><p>Let’s have a look a the links of the world cups 2014, 2018 and 2022</p><figure><pre>https://en.wikipedia.org/wiki/2014_FIFA_World_Cup
https://en.wikipedia.org/wiki/2018_FIFA_World_Cup
https://en.wikipedia.org/wiki/2022_FIFA_World_Cup</pre></figure><p>Have you noticed the pattern? The links are identical except for the year when a world cup took place.</p><p>We can re-write our <code>web</code> variable to consider this pattern:</p><figure><pre>web = f'https://en.wikipedia.org/wiki/{year}_FIFA_World_Cup'</pre></figure><p>And now we can put our code inside a function that takes as input the year.</p><figure><pre>import pandas as pd
from bs4 import BeautifulSoup
import requests


def get_matches(year):
    web = f'https://en.wikipedia.org/wiki/{year}_FIFA_World_Cup'
    response = requests.get(web)
    content = response.text
    soup = BeautifulSoup(content, 'lxml')
    matches = soup.find_all('div', class_='footballbox')

    home = []
    score = []
    away = []

    for match in matches:
        home.append(match.find('th', class_='fhome').get_text())
        score.append(match.find('th', class_='fscore').get_text())
        away.append(match.find('th', class_='faway').get_text())

    dict_football = {'home': home, 'score': score, 'away': away}
    df_football = pd.DataFrame(dict_football)
    df_football['year'] = year
    return df_football</pre></figure><p>Now it’s time to get historical data from 1930 to 2018 using our <code>get_matches </code>function.</p><figure><pre>years = [1930, 1934, 1938, 1950, 1954, 1958, 1962, 1966, 1970, 1974,
         1978, 1982, 1986, 1990, 1994, 1998, 2002, 2006, 2010, 2014,
         2018]

# results: historical data
fifa = [get_matches(year) for year in years]
df_fifa = pd.concat(fifa, ignore_index=True)
df_fifa.to_csv("fifa_worldcup_historical_data.csv", index=False)</pre></figure><p>We can also get the fixture of the coming World Cup Qatar 2022.</p><figure><pre>df_fixture = get_matches(2022)
df_fixture.to_csv('fifa_worldcup_fixture.csv', index=False)</pre></figure><p>That’s it! Now you should have 2 CSV files on your computer. One has the historical data and the other the fixture.</p><p>Note: The first file has some missing data because of some inconsistencies in the Wikipedia website (this tends to happen in real-world projects). In the following tutorial, we’ll scrape the missing data using Selenium.</p><p>Turn websites into datasets! <strong><a href="https://frankandrade.ck.page/ca38420833">Get my FREE Web Scraping Cheat Sheet by joining my email list with 10k+ people.</a></strong></p><p>If you enjoy reading stories like these and want to support me as a writer, consider signing up to become a Medium member. It’s $5 a month, giving you unlimited access to thousands of Python guides and Data science articles. If you sign up using <a href="https://frank-andrade.medium.com/membership">my link</a>, I’ll earn a small commission with no extra cost to you.</p><blockquote><p><strong><a href="https://frank-andrade.medium.com/membership">Join Medium with my referral link — Frank Andrade</a></strong>
<em>As a Medium member, a portion of your membership fee goes to writers you read, and you get full access to every story…</em><a href="https://frank-andrade.medium.com/membership">frank-andrade.medium.com</a></p></blockquote></section></article></div></div>
		</article>
		

		<!-- Template to use for page footer -->
		<template class="footer-template">
			<div class="text center">
				<span class="pageNumber"></span>
			</div>
		</template>
	</body>
</html>
